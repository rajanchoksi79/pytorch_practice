{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "workflow.ipynb",
      "authorship_tag": "ABX9TyO3behb49Zaz9OKrgq0fLNR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajanchoksi79/pytorch_practice/blob/main/workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3vcMWiKCSd9",
        "outputId": "04b76f8d-1cc2-4413-fb63-1415979ef600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | MAE Train Loss: 0.31288138031959534 | MAE Test Loss | 0.48106518387794495 \n",
            "Epoch 10 | MAE Train Loss: 0.1976713240146637 | MAE Test Loss | 0.3463551998138428 \n",
            "Epoch 20 | MAE Train Loss: 0.08908725529909134 | MAE Test Loss | 0.21729660034179688 \n",
            "Epoch 30 | MAE Train Loss: 0.053148526698350906 | MAE Test Loss | 0.14464017748832703 \n",
            "Epoch 40 | MAE Train Loss: 0.04543796554207802 | MAE Test Loss | 0.11360953003168106 \n",
            "Epoch 50 | MAE Train Loss: 0.04167863354086876 | MAE Test Loss | 0.09919948130846024 \n",
            "Epoch 60 | MAE Train Loss: 0.03818932920694351 | MAE Test Loss | 0.08886633068323135 \n",
            "Epoch 70 | MAE Train Loss: 0.03476089984178543 | MAE Test Loss | 0.0805937647819519 \n",
            "Epoch 80 | MAE Train Loss: 0.03132382780313492 | MAE Test Loss | 0.07232122868299484 \n",
            "Epoch 90 | MAE Train Loss: 0.02788739837706089 | MAE Test Loss | 0.06473556160926819 \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# create known parameters\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# create data\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "\n",
        "X[:10], y[:10]\n",
        "\n",
        "# crerating training and testing data\n",
        "train_split = int(0.8 * len(X))\n",
        "\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "#visuling data\n",
        "def plot_predictions(train_data=X_train, train_labels=y_train, test_data=X_test, test_labels=y_test, predictions=None):\n",
        "  plt.figure(figsize=(10, 7))\n",
        "\n",
        "  #plot training data into blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "\n",
        "  #plot testing data into green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "  if predictions is not None:\n",
        "    # Plot the predictions in red (predictions were made on the test data)\n",
        "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\": 14});\n",
        "\n",
        "# plot_predictions()\n",
        "\n",
        "# create a linear regression model class\n",
        "class LinearRegressionModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.randn(1, dtype=torch.float), requires_grad=True)\n",
        "    self.bias = nn.Parameter(torch.randn(1, dtype=torch.float), requires_grad=True)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.weight * x + self.bias\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "with torch.inference_mode():\n",
        "  y_pred = model_0(X_test)\n",
        "\n",
        "# print(f\"Number of testing samples: {len(X_test)}\")\n",
        "# print(f\"Number of predictions made: {len(y_pred)}\")\n",
        "# print(f\"Predicted values: \\n{y_pred}\")\n",
        "\n",
        "# plot_predictions(predictions=y_pred)\n",
        "\n",
        "loss_fn = nn.L1Loss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "epoch_count = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_0.train()\n",
        "  y_pred = model_0(X_train)\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_pred = model_0(X_test)\n",
        "    test_loss = loss_fn(test_pred, y_test.type(torch.float))\n",
        "    if epoch % 10 == 0:\n",
        "      epoch_count.append(epoch)\n",
        "      train_loss_values.append(loss.detach().numpy())\n",
        "      test_loss_values.append(test_loss.detach().numpy())\n",
        "      print(f\"Epoch {epoch} | MAE Train Loss: {loss} | MAE Test Loss | {test_loss} \")"
      ]
    }
  ]
}